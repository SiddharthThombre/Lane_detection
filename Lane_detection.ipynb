{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Function to process the video\n",
        "def process_local_video(video_path):\n",
        "    # Read the video using OpenCV VideoCapture\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Process the video frame by frame\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Detect lanes\n",
        "        lanes_frame = detect_lanes(frame)\n",
        "\n",
        "        # Display the resulting frame\n",
        "        cv2.imshow('Lanes Detection', lanes_frame)\n",
        "\n",
        "        # Press 'q' to exit\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    # Release video capture\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "# Function to detect lanes in a frame\n",
        "def detect_lanes(frame):\n",
        "    # Convert frame to grayscale\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Gaussian blur\n",
        "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "    # Apply Canny edge detection\n",
        "    edges = cv2.Canny(blur, 50, 150)\n",
        "\n",
        "    # Define region of interest (ROI)\n",
        "    height, width = frame.shape[:2]\n",
        "    mask = np.zeros_like(edges)\n",
        "    roi = np.array([[(0, height), (width // 2, height // 2), (width, height)]], dtype=np.int32)\n",
        "    cv2.fillPoly(mask, roi, 255)\n",
        "    masked_edges = cv2.bitwise_and(edges, mask)\n",
        "\n",
        "    # Apply Hough Transform to detect lines\n",
        "    lines = cv2.HoughLinesP(masked_edges, 2, np.pi / 180, 100, np.array([]), minLineLength=40, maxLineGap=5)\n",
        "\n",
        "    # Draw lines on a blank image\n",
        "    line_image = np.zeros_like(frame)\n",
        "    for line in lines:\n",
        "        x1, y1, x2, y2 = line[0]\n",
        "        cv2.line(line_image, (x1, y1), (x2, y2), (0, 255, 0), 5)\n",
        "\n",
        "    # Combine detected lines with original frame\n",
        "    lanes_image = cv2.addWeighted(frame, 0.8, line_image, 1, 0)\n",
        "\n",
        "    return lanes_image\n",
        "\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # Input local video file path\n",
        "    video_path = \"/Users/ruksarchaudhary/Desktop/project/Face_Recognition/.venv/faces/lanes_clip.mp4\"\n",
        "\n",
        "    # Process the local video\n",
        "    process_local_video(video_path)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "4F6piWqxBF00"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}